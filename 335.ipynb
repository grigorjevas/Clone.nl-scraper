{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "335.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDJEM6bO_i_s"
      },
      "source": [
        "# Module 3: Machine Learning\n",
        "\n",
        "## Sprint 3: Introduction to Natural Language Processing and Computer Vision\n",
        "\n",
        "## Kaggle competition - don't overfit!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJqcoXGu_i_2"
      },
      "source": [
        "## Background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9A5_Ddb_i_2"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DdjOIwa_i_2"
      },
      "source": [
        "Participating in Kaggle competitions is an efficient way to learn some aspects of Machine Learning. You can read solutions made public by the others, participate in the discussions to talk about solution ideas and test them by submitting them for evaluation.\n",
        "\n",
        "The metric used for evaluation can vary from competition to competition, but the idea remains the same - build a model that is as accurate as possible on the testing set. In industry, there are other factors to consider when building machine learning models - inference time, solution complexity, maintainability and so on. However, even though you only learn a subset of the required skills while participating in Kaggle competitions, it is quite a fun way to learn by doing it, so let's participate in one of the competitions again!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3emkt_7_i_3"
      },
      "source": [
        "## The competition\n",
        "\n",
        "Even though we spent quite some time on natural language processing and computer vision during the sprint, the most accurate models on these types of data usually involves deep learning, that you will learn about in the upcoming course! In this project, the main goal will be to understand the concept of overfitting as deeply as possible, which essentially means fitting the training data very well at the expense of a model that generalizes and works well on other samples.\n",
        "\n",
        "To learn about the concept of overfitting, we will participate in the following Kaggle competition:\n",
        "\n",
        "- https://www.kaggle.com/c/dont-overfit-ii\n",
        "\n",
        "IMPORTANT: download the data from here - https://www.kaggle.com/sahiltinky/org-dataset-dont-overfitii, as the evaluation is done on an older dataset version than the one available at the competition data section.\n",
        "\n",
        "For help, you can look at some of the notebooks by other competitors. However, try to write code by yourself, as even though you will always be able to consult external resources while working as a professional, the main thing right now is to learn by first trying it yourself.\n",
        "\n",
        "Some notebooks that are worth exploring:\n",
        "\n",
        "- https://www.kaggle.com/artgor/how-to-not-overfit\n",
        "- https://www.kaggle.com/rafjaa/dealing-with-very-small-datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCdpHOfN_i_3"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aldafC6t_i_3"
      },
      "source": [
        "## Concepts to explore\n",
        "\n",
        "- https://towardsdatascience.com/how-to-improve-your-kaggle-competition-leaderboard-ranking-bcd16643eddf\n",
        "- https://opendatascience.com/10-tips-to-get-started-with-kaggle/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-nPHTWI_i_4"
      },
      "source": [
        "## Requirements\n",
        "\n",
        "- Data exploration\n",
        "- Feature engineering\n",
        "- At least several different models built and compared to each other on the validation set and on the public and private leaderboards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzFmrPEY_i_4"
      },
      "source": [
        "## Evaluation criteria\n",
        "\n",
        "- Private leaderboard score (target is better than 0.8)\n",
        "- How simple is the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVjBSm4V_i_4"
      },
      "source": [
        "\n",
        "## Sample correction questions\n",
        "\n",
        "During a correction, you may get asked questions that test your understanding of covered topics.\n",
        "\n",
        "- Is it possible to use standard machine learning algorithms, such as logistic regression and random forests, when working with text? If yes, what has to be done and how?\n",
        "- You train a machine learning model and get a low validation accuracy. What other metrics you could check to better understand the problem? What are some of the ways to improve the validation accuracy?\n",
        "- How does looking at the validation accuracy, confusion matrix and important features complement each other when evaluating the model's performance?\n",
        "- How to make sure that the model that was deployed to production performs well?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO-5og1MW4BQ"
      },
      "source": [
        "# Competition code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9KwIwvnW6ui"
      },
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "\n",
        "from scipy.stats import uniform as sp_randFloat\n",
        "from scipy.stats import randint as sp_randInt\n",
        "\n",
        "from sklearn import set_config\n",
        "set_config(display=\"diagram\")\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "RANDOM_STATE = 3"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvbdxKwFXWa_",
        "outputId": "5b50c5a1-0b39-47dc-db86-5088095c6f56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load the data\n",
        "train_df = pd.read_csv(\"~/Google Drive/Data/335_dont_overfit/train.csv\", index_col=\"id\")\n",
        "test_df = pd.read_csv(\"~/Google Drive/Data/335_dont_overfit/test.csv\", index_col=\"id\")\n",
        "\n",
        "train_df.shape, test_df.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((250, 301), (19750, 300))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i_WUao8aczv"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QE2Z7bOX46G",
        "outputId": "baf4be05-310b-480e-eb7c-11d7ac764de9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    target      0      1      2      3      4      5      6      7      8  \\\n",
              "id                                                                          \n",
              "0      1.0 -0.098  2.165  0.681 -0.614  1.309 -0.455 -0.236  0.276 -2.246   \n",
              "1      0.0  1.081 -0.973 -0.383  0.326 -0.428  0.317  1.172  0.352  0.004   \n",
              "2      1.0 -0.523 -0.089 -0.348  0.148 -0.022  0.404 -0.023 -0.172  0.137   \n",
              "3      1.0  0.067 -0.021  0.392 -1.637 -0.446 -0.725 -1.035  0.834  0.503   \n",
              "4      1.0  2.347 -0.831  0.511 -0.021  1.225  1.594  0.585  1.509 -0.012   \n",
              "\n",
              "    ...    290    291    292    293    294    295    296    297    298    299  \n",
              "id  ...                                                                        \n",
              "0   ...  0.867  1.347  0.504 -0.649  0.672 -2.097  1.051 -0.414  1.038 -1.065  \n",
              "1   ... -0.165 -1.695 -1.257  1.359 -0.808 -1.624 -0.458 -1.099 -0.936  0.973  \n",
              "2   ...  0.013  0.263 -1.222  0.726  1.444 -1.165 -1.544  0.004  0.800 -1.211  \n",
              "3   ... -0.404  0.640 -0.595 -0.966  0.900  0.467 -0.562 -0.254 -0.533  0.238  \n",
              "4   ...  0.898  0.134  2.415 -0.996 -1.006  1.378  1.246  1.478  0.428  0.253  \n",
              "\n",
              "[5 rows x 301 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>299</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.098</td>\n",
              "      <td>2.165</td>\n",
              "      <td>0.681</td>\n",
              "      <td>-0.614</td>\n",
              "      <td>1.309</td>\n",
              "      <td>-0.455</td>\n",
              "      <td>-0.236</td>\n",
              "      <td>0.276</td>\n",
              "      <td>-2.246</td>\n",
              "      <td>...</td>\n",
              "      <td>0.867</td>\n",
              "      <td>1.347</td>\n",
              "      <td>0.504</td>\n",
              "      <td>-0.649</td>\n",
              "      <td>0.672</td>\n",
              "      <td>-2.097</td>\n",
              "      <td>1.051</td>\n",
              "      <td>-0.414</td>\n",
              "      <td>1.038</td>\n",
              "      <td>-1.065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.081</td>\n",
              "      <td>-0.973</td>\n",
              "      <td>-0.383</td>\n",
              "      <td>0.326</td>\n",
              "      <td>-0.428</td>\n",
              "      <td>0.317</td>\n",
              "      <td>1.172</td>\n",
              "      <td>0.352</td>\n",
              "      <td>0.004</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.165</td>\n",
              "      <td>-1.695</td>\n",
              "      <td>-1.257</td>\n",
              "      <td>1.359</td>\n",
              "      <td>-0.808</td>\n",
              "      <td>-1.624</td>\n",
              "      <td>-0.458</td>\n",
              "      <td>-1.099</td>\n",
              "      <td>-0.936</td>\n",
              "      <td>0.973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.523</td>\n",
              "      <td>-0.089</td>\n",
              "      <td>-0.348</td>\n",
              "      <td>0.148</td>\n",
              "      <td>-0.022</td>\n",
              "      <td>0.404</td>\n",
              "      <td>-0.023</td>\n",
              "      <td>-0.172</td>\n",
              "      <td>0.137</td>\n",
              "      <td>...</td>\n",
              "      <td>0.013</td>\n",
              "      <td>0.263</td>\n",
              "      <td>-1.222</td>\n",
              "      <td>0.726</td>\n",
              "      <td>1.444</td>\n",
              "      <td>-1.165</td>\n",
              "      <td>-1.544</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.800</td>\n",
              "      <td>-1.211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.067</td>\n",
              "      <td>-0.021</td>\n",
              "      <td>0.392</td>\n",
              "      <td>-1.637</td>\n",
              "      <td>-0.446</td>\n",
              "      <td>-0.725</td>\n",
              "      <td>-1.035</td>\n",
              "      <td>0.834</td>\n",
              "      <td>0.503</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.404</td>\n",
              "      <td>0.640</td>\n",
              "      <td>-0.595</td>\n",
              "      <td>-0.966</td>\n",
              "      <td>0.900</td>\n",
              "      <td>0.467</td>\n",
              "      <td>-0.562</td>\n",
              "      <td>-0.254</td>\n",
              "      <td>-0.533</td>\n",
              "      <td>0.238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.347</td>\n",
              "      <td>-0.831</td>\n",
              "      <td>0.511</td>\n",
              "      <td>-0.021</td>\n",
              "      <td>1.225</td>\n",
              "      <td>1.594</td>\n",
              "      <td>0.585</td>\n",
              "      <td>1.509</td>\n",
              "      <td>-0.012</td>\n",
              "      <td>...</td>\n",
              "      <td>0.898</td>\n",
              "      <td>0.134</td>\n",
              "      <td>2.415</td>\n",
              "      <td>-0.996</td>\n",
              "      <td>-1.006</td>\n",
              "      <td>1.378</td>\n",
              "      <td>1.246</td>\n",
              "      <td>1.478</td>\n",
              "      <td>0.428</td>\n",
              "      <td>0.253</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 301 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HarM3ryYW6FE"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS6oG-kjW6aO",
        "outputId": "0a412518-9e5f-40db-a929-3dba74940b49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "train_df.describe()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           target           0           1           2           3           4  \\\n",
              "count  250.000000  250.000000  250.000000  250.000000  250.000000  250.000000   \n",
              "mean     0.640000    0.023292   -0.026872    0.167404    0.001904    0.001588   \n",
              "std      0.480963    0.998354    1.009314    1.021709    1.011751    1.035411   \n",
              "min      0.000000   -2.319000   -2.931000   -2.477000   -2.359000   -2.566000   \n",
              "25%      0.000000   -0.644750   -0.739750   -0.425250   -0.686500   -0.659000   \n",
              "50%      1.000000   -0.015500    0.057000    0.184000   -0.016500   -0.023000   \n",
              "75%      1.000000    0.677000    0.620750    0.805000    0.720000    0.735000   \n",
              "max      1.000000    2.567000    2.419000    3.392000    2.771000    2.901000   \n",
              "\n",
              "                5           6           7           8  ...         290  \\\n",
              "count  250.000000  250.000000  250.000000  250.000000  ...  250.000000   \n",
              "mean    -0.007304    0.032052    0.078412   -0.036920  ...    0.044652   \n",
              "std      0.955700    1.006657    0.939731    0.963688  ...    1.011416   \n",
              "min     -2.845000   -2.976000   -3.444000   -2.768000  ...   -2.804000   \n",
              "25%     -0.643750   -0.675000   -0.550750   -0.689500  ...   -0.617000   \n",
              "50%      0.037500    0.060500    0.183500   -0.012500  ...    0.067500   \n",
              "75%      0.660500    0.783250    0.766250    0.635000  ...    0.797250   \n",
              "max      2.793000    2.546000    2.846000    2.512000  ...    2.865000   \n",
              "\n",
              "              291         292         293         294         295         296  \\\n",
              "count  250.000000  250.000000  250.000000  250.000000  250.000000  250.000000   \n",
              "mean     0.126344    0.018436   -0.012092   -0.065720   -0.106112    0.046472   \n",
              "std      0.972567    0.954229    0.960630    1.057414    1.038389    0.967661   \n",
              "min     -2.443000   -2.757000   -2.466000   -3.287000   -3.072000   -2.634000   \n",
              "25%     -0.510500   -0.535750   -0.657000   -0.818500   -0.821000   -0.605500   \n",
              "50%      0.091000    0.057500   -0.021000   -0.009000   -0.079500    0.009500   \n",
              "75%      0.804250    0.631500    0.650250    0.739500    0.493000    0.683000   \n",
              "max      2.801000    2.736000    2.596000    2.226000    3.131000    3.236000   \n",
              "\n",
              "              297         298         299  \n",
              "count  250.000000  250.000000  250.000000  \n",
              "mean     0.006452    0.009372   -0.128952  \n",
              "std      0.998984    1.008099    0.971219  \n",
              "min     -2.776000   -3.211000   -3.500000  \n",
              "25%     -0.751250   -0.550000   -0.754250  \n",
              "50%      0.005500   -0.009000   -0.132500  \n",
              "75%      0.794250    0.654250    0.503250  \n",
              "max      2.626000    3.530000    2.771000  \n",
              "\n",
              "[8 rows x 301 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>299</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>250.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>250.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.023292</td>\n",
              "      <td>-0.026872</td>\n",
              "      <td>0.167404</td>\n",
              "      <td>0.001904</td>\n",
              "      <td>0.001588</td>\n",
              "      <td>-0.007304</td>\n",
              "      <td>0.032052</td>\n",
              "      <td>0.078412</td>\n",
              "      <td>-0.036920</td>\n",
              "      <td>...</td>\n",
              "      <td>0.044652</td>\n",
              "      <td>0.126344</td>\n",
              "      <td>0.018436</td>\n",
              "      <td>-0.012092</td>\n",
              "      <td>-0.065720</td>\n",
              "      <td>-0.106112</td>\n",
              "      <td>0.046472</td>\n",
              "      <td>0.006452</td>\n",
              "      <td>0.009372</td>\n",
              "      <td>-0.128952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.480963</td>\n",
              "      <td>0.998354</td>\n",
              "      <td>1.009314</td>\n",
              "      <td>1.021709</td>\n",
              "      <td>1.011751</td>\n",
              "      <td>1.035411</td>\n",
              "      <td>0.955700</td>\n",
              "      <td>1.006657</td>\n",
              "      <td>0.939731</td>\n",
              "      <td>0.963688</td>\n",
              "      <td>...</td>\n",
              "      <td>1.011416</td>\n",
              "      <td>0.972567</td>\n",
              "      <td>0.954229</td>\n",
              "      <td>0.960630</td>\n",
              "      <td>1.057414</td>\n",
              "      <td>1.038389</td>\n",
              "      <td>0.967661</td>\n",
              "      <td>0.998984</td>\n",
              "      <td>1.008099</td>\n",
              "      <td>0.971219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.319000</td>\n",
              "      <td>-2.931000</td>\n",
              "      <td>-2.477000</td>\n",
              "      <td>-2.359000</td>\n",
              "      <td>-2.566000</td>\n",
              "      <td>-2.845000</td>\n",
              "      <td>-2.976000</td>\n",
              "      <td>-3.444000</td>\n",
              "      <td>-2.768000</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.804000</td>\n",
              "      <td>-2.443000</td>\n",
              "      <td>-2.757000</td>\n",
              "      <td>-2.466000</td>\n",
              "      <td>-3.287000</td>\n",
              "      <td>-3.072000</td>\n",
              "      <td>-2.634000</td>\n",
              "      <td>-2.776000</td>\n",
              "      <td>-3.211000</td>\n",
              "      <td>-3.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.644750</td>\n",
              "      <td>-0.739750</td>\n",
              "      <td>-0.425250</td>\n",
              "      <td>-0.686500</td>\n",
              "      <td>-0.659000</td>\n",
              "      <td>-0.643750</td>\n",
              "      <td>-0.675000</td>\n",
              "      <td>-0.550750</td>\n",
              "      <td>-0.689500</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.617000</td>\n",
              "      <td>-0.510500</td>\n",
              "      <td>-0.535750</td>\n",
              "      <td>-0.657000</td>\n",
              "      <td>-0.818500</td>\n",
              "      <td>-0.821000</td>\n",
              "      <td>-0.605500</td>\n",
              "      <td>-0.751250</td>\n",
              "      <td>-0.550000</td>\n",
              "      <td>-0.754250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.015500</td>\n",
              "      <td>0.057000</td>\n",
              "      <td>0.184000</td>\n",
              "      <td>-0.016500</td>\n",
              "      <td>-0.023000</td>\n",
              "      <td>0.037500</td>\n",
              "      <td>0.060500</td>\n",
              "      <td>0.183500</td>\n",
              "      <td>-0.012500</td>\n",
              "      <td>...</td>\n",
              "      <td>0.067500</td>\n",
              "      <td>0.091000</td>\n",
              "      <td>0.057500</td>\n",
              "      <td>-0.021000</td>\n",
              "      <td>-0.009000</td>\n",
              "      <td>-0.079500</td>\n",
              "      <td>0.009500</td>\n",
              "      <td>0.005500</td>\n",
              "      <td>-0.009000</td>\n",
              "      <td>-0.132500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.677000</td>\n",
              "      <td>0.620750</td>\n",
              "      <td>0.805000</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.660500</td>\n",
              "      <td>0.783250</td>\n",
              "      <td>0.766250</td>\n",
              "      <td>0.635000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.797250</td>\n",
              "      <td>0.804250</td>\n",
              "      <td>0.631500</td>\n",
              "      <td>0.650250</td>\n",
              "      <td>0.739500</td>\n",
              "      <td>0.493000</td>\n",
              "      <td>0.683000</td>\n",
              "      <td>0.794250</td>\n",
              "      <td>0.654250</td>\n",
              "      <td>0.503250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.567000</td>\n",
              "      <td>2.419000</td>\n",
              "      <td>3.392000</td>\n",
              "      <td>2.771000</td>\n",
              "      <td>2.901000</td>\n",
              "      <td>2.793000</td>\n",
              "      <td>2.546000</td>\n",
              "      <td>2.846000</td>\n",
              "      <td>2.512000</td>\n",
              "      <td>...</td>\n",
              "      <td>2.865000</td>\n",
              "      <td>2.801000</td>\n",
              "      <td>2.736000</td>\n",
              "      <td>2.596000</td>\n",
              "      <td>2.226000</td>\n",
              "      <td>3.131000</td>\n",
              "      <td>3.236000</td>\n",
              "      <td>2.626000</td>\n",
              "      <td>3.530000</td>\n",
              "      <td>2.771000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 301 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b5BgzPJYnAZ",
        "outputId": "2341379e-51f0-408c-de4f-007a02e2b62c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "test_df.describe()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  0             1             2             3             4  \\\n",
              "count  19750.000000  19750.000000  19750.000000  19750.000000  19750.000000   \n",
              "mean      -0.014043      0.000972      0.005145     -0.003525      0.003394   \n",
              "std        1.003779      0.993955      1.000809      1.008545      1.002826   \n",
              "min       -4.070000     -3.664000     -4.258000     -4.140000     -4.411000   \n",
              "25%       -0.688750     -0.667000     -0.668000     -0.686000     -0.671000   \n",
              "50%       -0.006000      0.001000      0.017000     -0.006000      0.007000   \n",
              "75%        0.664000      0.676000      0.681000      0.682000      0.676000   \n",
              "max        3.767000      3.864000      3.866000      3.871000      3.955000   \n",
              "\n",
              "                  5             6             7             8             9  \\\n",
              "count  19750.000000  19750.000000  19750.000000  19750.000000  19750.000000   \n",
              "mean       0.002738      0.004213     -0.010618     -0.003211     -0.002738   \n",
              "std        1.002917      0.994315      0.997972      0.996938      1.000688   \n",
              "min       -3.586000     -3.953000     -3.906000     -4.203000     -4.024000   \n",
              "25%       -0.679000     -0.673000     -0.680000     -0.667000     -0.677000   \n",
              "50%        0.005000      0.014000     -0.014000     -0.003000     -0.007000   \n",
              "75%        0.684750      0.670000      0.660750      0.671000      0.673000   \n",
              "max        3.819000      3.954000      3.669000      3.948000      3.812000   \n",
              "\n",
              "       ...           290           291           292           293  \\\n",
              "count  ...  19750.000000  19750.000000  19750.000000  19750.000000   \n",
              "mean   ...      0.002577     -0.010130     -0.003961      0.012793   \n",
              "std    ...      0.996314      0.996511      0.999788      1.014520   \n",
              "min    ...     -3.688000     -3.877000     -3.599000     -3.650000   \n",
              "25%    ...     -0.660000     -0.675000     -0.684750     -0.672000   \n",
              "50%    ...     -0.006000     -0.015000     -0.004000      0.007000   \n",
              "75%    ...      0.667000      0.654000      0.680000      0.694000   \n",
              "max    ...      3.619000      3.829000      3.717000      5.092000   \n",
              "\n",
              "                294           295           296           297           298  \\\n",
              "count  19750.000000  19750.000000  19750.000000  19750.000000  19750.000000   \n",
              "mean       0.009063      0.007512     -0.004283     -0.001203      0.013076   \n",
              "std        0.994000      0.999559      0.996270      1.003705      0.996285   \n",
              "min       -3.865000     -3.814000     -3.835000     -3.908000     -3.581000   \n",
              "25%       -0.656750     -0.664000     -0.665000     -0.680000     -0.663000   \n",
              "50%        0.001000      0.001000     -0.001000     -0.010000      0.016000   \n",
              "75%        0.682000      0.685000      0.669000      0.673000      0.686000   \n",
              "max        5.125000      3.681000      3.716000      3.932000      3.764000   \n",
              "\n",
              "                299  \n",
              "count  19750.000000  \n",
              "mean       0.000070  \n",
              "std        1.000596  \n",
              "min       -4.135000  \n",
              "25%       -0.675000  \n",
              "50%        0.007000  \n",
              "75%        0.676000  \n",
              "max        4.070000  \n",
              "\n",
              "[8 rows x 300 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>299</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>19750.000000</td>\n",
              "      <td>19750.000000</td>\n",
              "      <td>19750.000000</td>\n",
              "      <td>19750.000000</td>\n",
              "      <td>19750.000000</td>\n",
              "      <td>19750.000000</td>\n",
              "      <td>19750.000000</td>\n",
              "      <td>19750.000000</td>\n",
              "      <td>19750.000000</td>\n",
              "      <td>19750.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>19750.000000</td>\n",
              "      <td>19750.000000</td>\n",
              "      <td>19750.000000</td>\n",
              "      <td>19750.000000</td>\n",
              "      <td>19750.000000</td>\n",
              "      <td>19750.000000</td>\n",
              "      <td>19750.000000</td>\n",
              "      <td>19750.000000</td>\n",
              "      <td>19750.000000</td>\n",
              "      <td>19750.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-0.014043</td>\n",
              "      <td>0.000972</td>\n",
              "      <td>0.005145</td>\n",
              "      <td>-0.003525</td>\n",
              "      <td>0.003394</td>\n",
              "      <td>0.002738</td>\n",
              "      <td>0.004213</td>\n",
              "      <td>-0.010618</td>\n",
              "      <td>-0.003211</td>\n",
              "      <td>-0.002738</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002577</td>\n",
              "      <td>-0.010130</td>\n",
              "      <td>-0.003961</td>\n",
              "      <td>0.012793</td>\n",
              "      <td>0.009063</td>\n",
              "      <td>0.007512</td>\n",
              "      <td>-0.004283</td>\n",
              "      <td>-0.001203</td>\n",
              "      <td>0.013076</td>\n",
              "      <td>0.000070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.003779</td>\n",
              "      <td>0.993955</td>\n",
              "      <td>1.000809</td>\n",
              "      <td>1.008545</td>\n",
              "      <td>1.002826</td>\n",
              "      <td>1.002917</td>\n",
              "      <td>0.994315</td>\n",
              "      <td>0.997972</td>\n",
              "      <td>0.996938</td>\n",
              "      <td>1.000688</td>\n",
              "      <td>...</td>\n",
              "      <td>0.996314</td>\n",
              "      <td>0.996511</td>\n",
              "      <td>0.999788</td>\n",
              "      <td>1.014520</td>\n",
              "      <td>0.994000</td>\n",
              "      <td>0.999559</td>\n",
              "      <td>0.996270</td>\n",
              "      <td>1.003705</td>\n",
              "      <td>0.996285</td>\n",
              "      <td>1.000596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-4.070000</td>\n",
              "      <td>-3.664000</td>\n",
              "      <td>-4.258000</td>\n",
              "      <td>-4.140000</td>\n",
              "      <td>-4.411000</td>\n",
              "      <td>-3.586000</td>\n",
              "      <td>-3.953000</td>\n",
              "      <td>-3.906000</td>\n",
              "      <td>-4.203000</td>\n",
              "      <td>-4.024000</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.688000</td>\n",
              "      <td>-3.877000</td>\n",
              "      <td>-3.599000</td>\n",
              "      <td>-3.650000</td>\n",
              "      <td>-3.865000</td>\n",
              "      <td>-3.814000</td>\n",
              "      <td>-3.835000</td>\n",
              "      <td>-3.908000</td>\n",
              "      <td>-3.581000</td>\n",
              "      <td>-4.135000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.688750</td>\n",
              "      <td>-0.667000</td>\n",
              "      <td>-0.668000</td>\n",
              "      <td>-0.686000</td>\n",
              "      <td>-0.671000</td>\n",
              "      <td>-0.679000</td>\n",
              "      <td>-0.673000</td>\n",
              "      <td>-0.680000</td>\n",
              "      <td>-0.667000</td>\n",
              "      <td>-0.677000</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.660000</td>\n",
              "      <td>-0.675000</td>\n",
              "      <td>-0.684750</td>\n",
              "      <td>-0.672000</td>\n",
              "      <td>-0.656750</td>\n",
              "      <td>-0.664000</td>\n",
              "      <td>-0.665000</td>\n",
              "      <td>-0.680000</td>\n",
              "      <td>-0.663000</td>\n",
              "      <td>-0.675000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-0.006000</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.017000</td>\n",
              "      <td>-0.006000</td>\n",
              "      <td>0.007000</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>0.014000</td>\n",
              "      <td>-0.014000</td>\n",
              "      <td>-0.003000</td>\n",
              "      <td>-0.007000</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.006000</td>\n",
              "      <td>-0.015000</td>\n",
              "      <td>-0.004000</td>\n",
              "      <td>0.007000</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>-0.001000</td>\n",
              "      <td>-0.010000</td>\n",
              "      <td>0.016000</td>\n",
              "      <td>0.007000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.664000</td>\n",
              "      <td>0.676000</td>\n",
              "      <td>0.681000</td>\n",
              "      <td>0.682000</td>\n",
              "      <td>0.676000</td>\n",
              "      <td>0.684750</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.660750</td>\n",
              "      <td>0.671000</td>\n",
              "      <td>0.673000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.667000</td>\n",
              "      <td>0.654000</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.694000</td>\n",
              "      <td>0.682000</td>\n",
              "      <td>0.685000</td>\n",
              "      <td>0.669000</td>\n",
              "      <td>0.673000</td>\n",
              "      <td>0.686000</td>\n",
              "      <td>0.676000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.767000</td>\n",
              "      <td>3.864000</td>\n",
              "      <td>3.866000</td>\n",
              "      <td>3.871000</td>\n",
              "      <td>3.955000</td>\n",
              "      <td>3.819000</td>\n",
              "      <td>3.954000</td>\n",
              "      <td>3.669000</td>\n",
              "      <td>3.948000</td>\n",
              "      <td>3.812000</td>\n",
              "      <td>...</td>\n",
              "      <td>3.619000</td>\n",
              "      <td>3.829000</td>\n",
              "      <td>3.717000</td>\n",
              "      <td>5.092000</td>\n",
              "      <td>5.125000</td>\n",
              "      <td>3.681000</td>\n",
              "      <td>3.716000</td>\n",
              "      <td>3.932000</td>\n",
              "      <td>3.764000</td>\n",
              "      <td>4.070000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 300 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31q56kPKYoWA",
        "outputId": "cf93f94b-917b-4a38-ed3b-ff723dcb5c58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def get_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n",
        "  missing_values = pd.DataFrame()\n",
        "  missing_values[\"counts\"] = df.isnull().sum().sort_values(ascending=False)\n",
        "  missing_values[\"percent\"] = missing_values[\"counts\"] / df.shape[0] * 100\n",
        "  return missing_values[missing_values[\"counts\"] > 0]\n",
        "\n",
        "if len(get_missing_values(train_df)) == 0:\n",
        "  print(\"No missing values in train dataset\")\n",
        "\n",
        "if len(get_missing_values(test_df)) == 0:\n",
        "  print(\"No missing values in test dataset\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No missing values in train dataset\n",
            "No missing values in test dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnXZN05pae1H"
      },
      "source": [
        "## Logistic regression on raw data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tkn-wvCKbFOm"
      },
      "source": [
        "x_train = train_df.drop([\"target\"], axis=\"columns\")\n",
        "y_train = train_df[\"target\"]"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkrNtG_nAcTE"
      },
      "source": [
        "# Scale data\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "x_train_scaled = pd.DataFrame(scaler.transform(x_train), columns=x_train.columns)\n",
        "x_test_scaled = pd.DataFrame(scaler.transform(test_df), columns=test_df.columns)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppbhJcSWn7oh"
      },
      "source": [
        "# features = [ '16', '33', '43', '45', '52', '63', '65', '73', '90', '91', '117', '133', '134', '149', '189', '199', '217', '237', '258', '295']"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtmHpEzBY92R",
        "outputId": "3e28eee4-a2fc-4f1e-deef-ef4be6f76a84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lr = LogisticRegression(\n",
        "    random_state=RANDOM_STATE,\n",
        "    penalty=\"l1\",\n",
        "    solver=\"saga\",\n",
        "    class_weight=\"balanced\",\n",
        "    C=0.2\n",
        ")\n",
        "\n",
        "scores = cross_val_score(lr, x_train_scaled[features], y_train, cv=5)\n",
        "scores, scores.mean()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.82, 0.78, 0.86, 0.82, 0.76]), 0.808)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7r9mTUn0NBo",
        "outputId": "c0f0ebe9-ed24-425e-8633-c988bd79c47d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lr_model = lr.fit(x_train[features], y_train)\n",
        "lr_pred = lr.predict(test_df[features])\n",
        "lr_pred.shape"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19750,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNgowbPQ-fTj",
        "outputId": "c6ce9213-1d25-443d-b031-22da2df18ec0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lr_pred"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 1., ..., 1., 1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owKDkI5z3_Fs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKY5_LIJ3-vx",
        "outputId": "f5fda40e-68d2-4c9e-dfd3-9cb8ced0a8b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lr = LogisticRegression(\n",
        "    random_state=RANDOM_STATE,\n",
        "    penalty=\"l1\",\n",
        "    solver=\"liblinear\",\n",
        "    class_weight=\"balanced\",\n",
        "    C=0.1,\n",
        "    max_iter=10000\n",
        ")\n",
        "\n",
        "lr_model = lr.fit(x_train, y_train)\n",
        "lr_pred = lr.predict(test_df)\n",
        "lr_pred.shape"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19750,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8OGvsDH3-td"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ttqeiVLcSie",
        "outputId": "b7624ecf-b51a-421f-fa19-17874d7e2f6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rfc = RandomForestClassifier(\n",
        "    random_state=RANDOM_STATE,\n",
        "    n_estimators=100\n",
        ")\n",
        "\n",
        "scores = cross_val_score(rfc, x_train[features], y_train, cv=5)\n",
        "scores, scores.mean()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.78, 0.86, 0.76, 0.82, 0.72]), 0.788)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvcEZupRkhbI",
        "outputId": "031187fc-42c4-4cc7-e20d-c92702d4f437",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nnet = MLPClassifier(\n",
        "    random_state=RANDOM_STATE,\n",
        "    hidden_layer_sizes=(300,2)\n",
        ")\n",
        "\n",
        "scores = cross_val_score(nnet, x_train_scaled[features], y_train, cv=5)\n",
        "scores, scores.mean()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.76, 0.8 , 0.86, 0.84, 0.74]), 0.8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVaw0r9pBxrs",
        "outputId": "2f717155-ea20-4aca-b177-f07d2e80ec93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "# Search for better parameters \n",
        "from itertools import product\n",
        "# make a map for hidden layer sizes\n",
        "# sizes = [16, 32, 64, 128]\n",
        "# shapes = (\n",
        "#     list(product(sizes, repeat=1))\n",
        "#     + list(product(sizes, repeat=2))\n",
        "#     + list(product(sizes, repeat=3))\n",
        "# )\n",
        "\n",
        "distributions = dict(\n",
        "    alpha=sp_randFloat(loc=0, scale=0.1),\n",
        "    # hidden_layer_sizes=shapes,\n",
        "    activation=['identity','logistic','tanh','relu'],\n",
        "    max_iter=[50, 100, 200, 300, 400, 500],\n",
        "    early_stopping=[True, False]\n",
        ")\n",
        "\n",
        "nnet_rs = RandomizedSearchCV(\n",
        "    nnet,\n",
        "    distributions,\n",
        "    n_iter=20,\n",
        "    cv=5,\n",
        "    verbose=1,\n",
        "    n_jobs=-1,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "nnet_rs.fit(x_train, y_train)\n",
        "\n",
        "print(f\"Best estimator: {nnet_rs.best_estimator_}\")\n",
        "print(f\"Best score: {nnet_rs.best_score_}\")\n",
        "print(f\"Best params: {nnet_rs.best_params_}\")"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "Best estimator: MLPClassifier(activation='logistic', alpha=0.05627700944910962,\n",
            "              hidden_layer_sizes=(300, 2), max_iter=400, random_state=3)\n",
            "Best score: 0.7080000000000001\n",
            "Best params: {'activation': 'logistic', 'alpha': 0.05627700944910962, 'early_stopping': False, 'max_iter': 400}\n",
            "CPU times: user 10.8 s, sys: 1.75 s, total: 12.5 s\n",
            "Wall time: 37.5 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD9pIGA1_a95",
        "outputId": "9f4b773c-7511-455e-f229-c7b30d2e3bab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nnet_model = nnet.fit(x_train_scaled[features], y_train)\n",
        "nnet_pred = nnet_model.predict(x_test_scaled[features])"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpqnpcngkzzF",
        "outputId": "d103ce7c-51d3-4a6a-a6b7-ac3f391408a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gbc = GradientBoostingClassifier(\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "scores = cross_val_score(gbc, x_train_scaled[features], y_train, cv=5)\n",
        "scores, scores.mean()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.7 , 0.64, 0.8 , 0.8 , 0.74]), 0.736)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3-tddJhaewV"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjD3sfwTZf4J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vtg8QmVZiMs"
      },
      "source": [
        "def generateSubmissionCsv(predictions, title):\n",
        "  submission = pd.read_csv(\"~/Google Drive/Data/335_dont_overfit/sample_submission.csv\")\n",
        "  submission.iloc[:,1] = predictions\n",
        "\n",
        "  now = datetime.now()\n",
        "  timestamp = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "\n",
        "  submission.to_csv(f\"{title}_submission_{timestamp}.csv\", index=False)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTbuZL2X-1oH"
      },
      "source": [
        "generateSubmissionCsv(lr_pred, \"lr_\")"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-kyEHPb_CHP"
      },
      "source": [
        "generateSubmissionCsv(nnet_pred, \"nn_first\")"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqTy4kX1_n5q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}