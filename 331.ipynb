{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "331.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5Agnxqnb5JB"
      },
      "source": [
        "# Module 3: Machine Learning\n",
        "\n",
        "## Sprint 3: Introduction to Natural Language Processing and Computer Vision\n",
        "\n",
        "## Subproject 1: Introduction to Natural Language Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIUbk_eUb5JL"
      },
      "source": [
        "Welcome to the third sprint of the Machine Learning course! In this sprint we will learn about how to process and build models on textual, visual data. What is more, we will learn about some more practical issues in machine learning - what are some common pitfalls and how to make sure that your model avoids them.\n",
        "\n",
        "There is a lot of textual data in the world and it comes in many forms - articles, questions, their answers, dialogues, comments, item names and their descriptions, etc. What is more, there are many languages and each has its own characteristics.\n",
        "\n",
        "While there are similarities in the way one should deal with various forms of textual data, there are also differences - sometimes a simple pattern matching algorithm can work very well, while sometimes you need complex architectures pre-trained on vast amounts of textual data to get a reasonably working model.\n",
        "\n",
        "In any case, having some practical skills of how to deal with textual data is very useful, and this will be the topic of this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAJiNfffb5JM"
      },
      "source": [
        "## Learning outcomes\n",
        "\n",
        "- Regular expressions\n",
        "- Converting text to a vector\n",
        "- Building models on textual data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stsI2CAwb5JM"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r_Nu4sNb5JM"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-8XpbXwb5JM"
      },
      "source": [
        "Let's begin learning about natural language processing from the Kaggle intro course:\n",
        "\n",
        "- https://www.kaggle.com/learn/natural-language-processing\n",
        "\n",
        "## Regular expressions\n",
        "\n",
        "Regular expressions is a powerful and convenient way to find a variety of different patterns in a text. Here is a good introductory tutorial about them:\n",
        "\n",
        "- https://scotch.io/tutorials/an-introduction-to-regex-in-python\n",
        "\n",
        "Additionally, it might be useful to skim through the documentation of a python package for regular expressions:\n",
        "\n",
        "- https://docs.python.org/3/library/re.html\n",
        "\n",
        "The best way to learn regular expressions is to practice them a lot, so let's do the exercises in the following link:\n",
        "\n",
        "- https://regexone.com\n",
        "\n",
        "## Vectorization\n",
        "\n",
        "Machine learning models usually work with vectors as the input, even though you will learn about some more complex models in the Deep Learning course. Converting textual data to a vector can be done in many ways, but one of the most common is using a bag of words approach - looking at the text as a collection of words and encoding that collection by a vector, where each vector coordinate corresponds to the existence (or count) of a specific word.\n",
        "\n",
        "Tf-idf vectorization is slightly more complex version of the count vectorization described above. The main idea of tf-idf is to encode very common words with lower values, as this might help the model not to put much weight to words that are generic, such as \"the\" or \"is\". To learn about count and tf-idf vectorization in more detail, read the following article:\n",
        "\n",
        "- https://www.analyticsvidhya.com/blog/2020/02/quick-introduction-bag-of-words-bow-tf-idf/\n",
        "\n",
        "Scikit-learn has some convenient objects for text vectorization. As usual, go through the parameters and try to understand as many of them as possible. Also, look at the examples:\n",
        "- http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHOIrPJ6b5JN"
      },
      "source": [
        "## NLP in practice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVw0ftNwb5JN"
      },
      "source": [
        "Let's begin by importing the modules we will need and setting the random state:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoGHRieEs2T2",
        "outputId": "a2385dd7-660b-447c-dac7-d3ce7bcc0cd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "!pip install scikit-learn==0.23"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn==0.23\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/c3/5f6e7317246d39b1921d3b697b4e419657eb728a1f02f9df4a019a35ccaf/scikit_learn-0.23.0-cp37-cp37m-manylinux1_x86_64.whl (7.3MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3MB 16.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23) (1.0.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.23.0 threadpoolctl-2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHnFNIkqb5JN"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets, metrics\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.pipeline import Pipeline\n",
        "import re\n",
        "\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')\n",
        "\n",
        "RANDOM_STATE = 7"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQJ_HwEzb5JO"
      },
      "source": [
        "We will be using the newsgroups dataset (https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html#loading-the-20-newsgroups-dataset), however, we will only use 4 categories as defined below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI4FdLkFb5JO"
      },
      "source": [
        "categories = ['comp.sys.mac.hardware', 'comp.windows.x', 'sci.med', 'sci.space']\n",
        "\n",
        "x_train = datasets.fetch_20newsgroups(subset='train', categories=categories)\n",
        "x_val = datasets.fetch_20newsgroups(subset='test', categories=categories)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDkmDGhMb5JO"
      },
      "source": [
        "We can look at our target values as below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ31GC2Kb5JO",
        "outputId": "b8cb88c3-69ac-45f2-ae95-95ca0f7f25e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_val.target"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 1, 3, ..., 1, 3, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMTejFHNb5JO"
      },
      "source": [
        "It is a bit inconvenient to see the targets as integers, as our targets are actually named and interpretable:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNnV2rCgb5JP",
        "outputId": "7a097941-8487-49aa-ec2a-84b34461431e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_val.target_names"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['comp.sys.mac.hardware', 'comp.windows.x', 'sci.med', 'sci.space']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebuUIK1Gb5JP"
      },
      "source": [
        "So let's build a dictionary mapping our target ids to their respective names:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5MgeOhmb5JP"
      },
      "source": [
        "target_id_to_name = {idx: x_val.target_names[idx] for idx in range(len(categories))}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOx7M0Dtb5JP"
      },
      "source": [
        "What is more, let's create a dataframe holding our input text and the target:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kd6RmA7b5JP",
        "outputId": "6045fc1a-61bc-43a7-f92a-a54130221364",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "train_df = pd.DataFrame({'text': x_train.data, 'target': x_train.target})\n",
        "val_df = pd.DataFrame({'text': x_val.data, 'target': x_val.target})\n",
        "train_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: jbh55289@uxa.cso.uiuc.edu (Josh Hopkins)...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: nodine@lcs.mit.edu (Mark H. Nodine)\\nSub...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: drisko@ics.com (Jason Drisko)\\nSubject: ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: straw@cam.nist.gov (Mike_Strawbridge_x38...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: petrack@vnet.IBM.COM\\nSubject: disabling...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target\n",
              "0  From: jbh55289@uxa.cso.uiuc.edu (Josh Hopkins)...       3\n",
              "1  From: nodine@lcs.mit.edu (Mark H. Nodine)\\nSub...       0\n",
              "2  From: drisko@ics.com (Jason Drisko)\\nSubject: ...       1\n",
              "3  From: straw@cam.nist.gov (Mike_Strawbridge_x38...       1\n",
              "4  From: petrack@vnet.IBM.COM\\nSubject: disabling...       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qPnCWH6b5JQ"
      },
      "source": [
        "We can now conveniently use our dictionary to map target ids to their names:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnZSx2C9b5JQ",
        "outputId": "6dd984d1-3af1-4d99-bbde-6e7c13a8fb80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "train_df['target'] = train_df['target'].map(target_id_to_name)\n",
        "val_df['target'] = val_df['target'].map(target_id_to_name)\n",
        "train_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: jbh55289@uxa.cso.uiuc.edu (Josh Hopkins)...</td>\n",
              "      <td>sci.space</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: nodine@lcs.mit.edu (Mark H. Nodine)\\nSub...</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: drisko@ics.com (Jason Drisko)\\nSubject: ...</td>\n",
              "      <td>comp.windows.x</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: straw@cam.nist.gov (Mike_Strawbridge_x38...</td>\n",
              "      <td>comp.windows.x</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: petrack@vnet.IBM.COM\\nSubject: disabling...</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text                 target\n",
              "0  From: jbh55289@uxa.cso.uiuc.edu (Josh Hopkins)...              sci.space\n",
              "1  From: nodine@lcs.mit.edu (Mark H. Nodine)\\nSub...  comp.sys.mac.hardware\n",
              "2  From: drisko@ics.com (Jason Drisko)\\nSubject: ...         comp.windows.x\n",
              "3  From: straw@cam.nist.gov (Mike_Strawbridge_x38...         comp.windows.x\n",
              "4  From: petrack@vnet.IBM.COM\\nSubject: disabling...  comp.sys.mac.hardware"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru_y7VdJb5JQ"
      },
      "source": [
        "Let's see what is the target distribution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7OFcknmb5JQ",
        "outputId": "e0230ceb-a60c-4cb9-94e5-afaa6b9255e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_df.groupby('target').size().sort_values(ascending=False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target\n",
              "sci.med                  594\n",
              "sci.space                593\n",
              "comp.windows.x           593\n",
              "comp.sys.mac.hardware    578\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qV_RAsyb5JQ"
      },
      "source": [
        "We see that the classes have approximately equal amount of samples. When the dataset is imbalanced, we should be careful when using the accuracy metric, as if 90% of the dataset has the same target, then it is trivial to build a model that always predicts it and is 90% accurate.\n",
        "\n",
        "To illustrate the use of regular expressions (check https://docs.python.org/3/library/re.html if something is unclear about the code below), let's use one that catches patterns that likely mean a price, like 5\\\\$ or \\\\\\$105:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWnaWGO2b5JQ",
        "outputId": "8a5a2607-c97e-428c-f7a5-4d38d10f6bb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "pattern = re.compile('(\\$\\d)|(\\d\\$)')\n",
        "train_df['contains_price'] = train_df['text'].apply(lambda x: pattern.search(x) is not None)\n",
        "train_df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>contains_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: jbh55289@uxa.cso.uiuc.edu (Josh Hopkins)...</td>\n",
              "      <td>sci.space</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: nodine@lcs.mit.edu (Mark H. Nodine)\\nSub...</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: drisko@ics.com (Jason Drisko)\\nSubject: ...</td>\n",
              "      <td>comp.windows.x</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: straw@cam.nist.gov (Mike_Strawbridge_x38...</td>\n",
              "      <td>comp.windows.x</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: petrack@vnet.IBM.COM\\nSubject: disabling...</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ... contains_price\n",
              "0  From: jbh55289@uxa.cso.uiuc.edu (Josh Hopkins)...  ...          False\n",
              "1  From: nodine@lcs.mit.edu (Mark H. Nodine)\\nSub...  ...          False\n",
              "2  From: drisko@ics.com (Jason Drisko)\\nSubject: ...  ...          False\n",
              "3  From: straw@cam.nist.gov (Mike_Strawbridge_x38...  ...          False\n",
              "4  From: petrack@vnet.IBM.COM\\nSubject: disabling...  ...          False\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr_Ya5lSb5JQ"
      },
      "source": [
        "We used the OR operator (|) to catch both the variant when the dollar sign is on the left and on the right of the digit. As the sign \\\\$ is a special symbol in regular expressions, we had to escape it by using \\\\. Finally, \\d is the pattern for any digit (0-9).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bdi9Mb3b5JQ"
      },
      "source": [
        "Let's look at the distribution of target values among those that have this feature as True, or, in other words, have a token that likely means a price in the text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtedRTt_b5JR",
        "outputId": "deb83eb3-180d-44a0-8486-c3f716a33561",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_df.query('contains_price == True').groupby('target').size().sort_values(ascending=False)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target\n",
              "sci.space                111\n",
              "comp.sys.mac.hardware     95\n",
              "sci.med                   36\n",
              "comp.windows.x            29\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R35SSBTib5JR"
      },
      "source": [
        "We see that prices are more likely to be mentioned in the space category, while it is less likely when the category is Windows. This might mean that adding this feature as additional feature to our machine learning model could help it distinguish between the categories. Various other regular expressions could be used to engineer new useful features too!\n",
        "\n",
        "Let's build a CountVectorizer object (as with all scikit-learn objects, refer to the scikit-learn documentation if its use is unclear):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg_fDsQib5JR"
      },
      "source": [
        "cv = CountVectorizer(\n",
        "    lowercase=True,\n",
        "    max_features=15000,\n",
        "    min_df=50,\n",
        "    binary=True,\n",
        "    ngram_range=(1,2),\n",
        "    strip_accents='ascii'\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9g3WTYjb5JR"
      },
      "source": [
        "As seen from above, we will be using word pairs as features as well as single words, and as the number of possible word pairs is large, we might end up with a feature vector having many dimensions (each dimension encoding for a unique word pair). It will be useful to also use an object to select the most important features (the most important word pairs):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nZ54EkDb5JR"
      },
      "source": [
        "feature_selector = SelectFromModel(\n",
        "    LogisticRegression(max_iter=1000),\n",
        "    threshold=0.05\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGKEJnHSb5JR"
      },
      "source": [
        "As a baseline model, let's pick logistic regression. It is also a great model when you have to deal with sparse (few non zero values) feature vectors of large dimensionality:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldz2CW2db5JR"
      },
      "source": [
        "model = LogisticRegression(max_iter=1000)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeDvjpP7b5JR"
      },
      "source": [
        "Now, let's put our:\n",
        "\n",
        "- preprocessor (CountVectorizer) that converts our text into a one-hot encoded vector, each dimension coding for the existence (or not) of a specific word pair\n",
        "- feature selector, that selects the word pairs with feature weight above a specific threshold\n",
        "- logistic regression model\n",
        "\n",
        "into a single pipeline object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCG2a1xab5JS"
      },
      "source": [
        "pipe = Pipeline(\n",
        "    steps=[\n",
        "        ('preprocessor', cv),\n",
        "        ('feature_selector', feature_selector),\n",
        "        ('model',  model)]\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pi0tRG4b5JS"
      },
      "source": [
        "Now we can fit our pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZynqBf5pb5JS",
        "outputId": "b8fc59e8-47aa-407a-a304-d1af40d43839",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "%%time\n",
        "pipe.fit(train_df['text'], train_df['target'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.63 s, sys: 53.7 ms, total: 3.68 s\n",
            "Wall time: 3.7 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"2cc4c9fc-f23a-4578-8ed1-bac82056cd3c\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"2cc4c9fc-f23a-4578-8ed1-bac82056cd3c\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('preprocessor',\n",
              "                 CountVectorizer(binary=True, max_features=15000, min_df=50,\n",
              "                                 ngram_range=(1, 2), strip_accents='ascii')),\n",
              "                ('feature_selector',\n",
              "                 SelectFromModel(estimator=LogisticRegression(max_iter=1000),\n",
              "                                 threshold=0.05)),\n",
              "                ('model', LogisticRegression(max_iter=1000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5b34a70d-af48-410a-8863-76833a953dc7\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"5b34a70d-af48-410a-8863-76833a953dc7\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(binary=True, max_features=15000, min_df=50, ngram_range=(1, 2),\n",
              "                strip_accents='ascii')</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5c1d9f69-093e-44c1-aea3-5fffac9cc9a0\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"5c1d9f69-093e-44c1-aea3-5fffac9cc9a0\">feature_selector: SelectFromModel</label><div class=\"sk-toggleable__content\"><pre>SelectFromModel(estimator=LogisticRegression(max_iter=1000), threshold=0.05)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"8e31b44d-cd5d-437e-bf65-299ebe2d0cc8\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"8e31b44d-cd5d-437e-bf65-299ebe2d0cc8\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"72861bb3-b7c2-4d22-a06c-e07c6689ce52\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"72861bb3-b7c2-4d22-a06c-e07c6689ce52\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('preprocessor',\n",
              "                 CountVectorizer(binary=True, max_features=15000, min_df=50,\n",
              "                                 ngram_range=(1, 2), strip_accents='ascii')),\n",
              "                ('feature_selector',\n",
              "                 SelectFromModel(estimator=LogisticRegression(max_iter=1000),\n",
              "                                 threshold=0.05)),\n",
              "                ('model', LogisticRegression(max_iter=1000))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5VZ6Uf6b5JS"
      },
      "source": [
        "Let's look at the accuracy scores of our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS5AAWw0b5JS",
        "outputId": "1549da05-17d3-40c2-d9d4-1aada1483b97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "train_df['target_prediction'] = pipe.predict(train_df['text'])\n",
        "print('Training accuracy is', metrics.accuracy_score(train_df['target'], train_df['target_prediction']))\n",
        "\n",
        "val_df['target_prediction'] = pipe.predict(val_df['text'])\n",
        "print('Validation accuracy is', metrics.accuracy_score(val_df['target'], val_df['target_prediction']))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy is 1.0\n",
            "Validation accuracy is 0.8560509554140128\n",
            "CPU times: user 1.8 s, sys: 11 ms, total: 1.81 s\n",
            "Wall time: 1.82 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luv8e6Zeb5JS"
      },
      "source": [
        "We see that our training set was fit perfectly, maybe we have too many features? Let's see how large is our vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_a1N6MQb5JS",
        "outputId": "ec97ece5-1c5f-42af-8e58-7e983173eee1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(cv.vocabulary_)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1607"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_neBZAIb5JT"
      },
      "source": [
        "In total there were 1607 word pairs used as features by the feature selector model. Let's see how many did it select based on the given threshold:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_j_z70bb5JT",
        "outputId": "1617753e-d4f5-4b29-a9fc-eec957c3e0cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sum(feature_selector.get_support())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1604"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBHWfBikb5JT"
      },
      "source": [
        "So 1604 features (word pairs) were selected out of 1607.\n",
        "\n",
        "Let's try to select the features a bit more selectively, using a higher threshold:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4lopMdOb5JT",
        "outputId": "5c36d107-0a09-4caa-cd00-3407e35292bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "feature_selector = SelectFromModel(\n",
        "    LogisticRegression(max_iter=1000),\n",
        "    threshold=0.4\n",
        ")\n",
        "\n",
        "pipe = Pipeline(\n",
        "    steps=[\n",
        "        ('preprocessor', cv),\n",
        "        ('feature_selector', feature_selector),\n",
        "        ('model',  model)]\n",
        ")\n",
        "\n",
        "pipe.fit(train_df['text'], train_df['target'])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"45d6324f-52b0-4549-8802-edde1521a246\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"45d6324f-52b0-4549-8802-edde1521a246\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('preprocessor',\n",
              "                 CountVectorizer(binary=True, max_features=15000, min_df=50,\n",
              "                                 ngram_range=(1, 2), strip_accents='ascii')),\n",
              "                ('feature_selector',\n",
              "                 SelectFromModel(estimator=LogisticRegression(max_iter=1000),\n",
              "                                 threshold=0.4)),\n",
              "                ('model', LogisticRegression(max_iter=1000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"432da9af-c941-41c2-971a-d490c222eaf4\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"432da9af-c941-41c2-971a-d490c222eaf4\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(binary=True, max_features=15000, min_df=50, ngram_range=(1, 2),\n",
              "                strip_accents='ascii')</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"f5440ae7-a696-47b1-98c3-223ea5fc6a90\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"f5440ae7-a696-47b1-98c3-223ea5fc6a90\">feature_selector: SelectFromModel</label><div class=\"sk-toggleable__content\"><pre>SelectFromModel(estimator=LogisticRegression(max_iter=1000), threshold=0.4)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"ecd9f561-e001-4860-8c8f-2a3da267f049\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"ecd9f561-e001-4860-8c8f-2a3da267f049\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a26b52db-277e-4425-a5ce-b6d44064e01e\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"a26b52db-277e-4425-a5ce-b6d44064e01e\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('preprocessor',\n",
              "                 CountVectorizer(binary=True, max_features=15000, min_df=50,\n",
              "                                 ngram_range=(1, 2), strip_accents='ascii')),\n",
              "                ('feature_selector',\n",
              "                 SelectFromModel(estimator=LogisticRegression(max_iter=1000),\n",
              "                                 threshold=0.4)),\n",
              "                ('model', LogisticRegression(max_iter=1000))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMza8ipmb5JT",
        "outputId": "6f489fc4-76b3-4ce8-a933-e58bf6b4b014",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "train_df['target_prediction'] = pipe.predict(train_df['text'])\n",
        "print('Training accuracy is', metrics.accuracy_score(train_df['target'], train_df['target_prediction']))\n",
        "\n",
        "val_df['target_prediction'] = pipe.predict(val_df['text'])\n",
        "print('Validation accuracy is', metrics.accuracy_score(val_df['target'], val_df['target_prediction']))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy is 1.0\n",
            "Validation accuracy is 0.8598726114649682\n",
            "CPU times: user 1.8 s, sys: 10.1 ms, total: 1.81 s\n",
            "Wall time: 1.84 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3aFIQGNb5JT",
        "outputId": "628643b5-5ed2-4631-97fd-94ab99ab4dce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sum(feature_selector.get_support())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "917"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU4ArfXKb5JT"
      },
      "source": [
        "With a more aggresive selection strategy we managed to improve the validation score while also reducing the number of features, the complexity and inference time of our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbceppV3b5JU"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Try to improve the above validation scores using a different model or different model hyper-parameters (you could also try using hyper-parameter optimization!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3mgNayev3kn"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform as sp_randFloat\n",
        "from scipy.stats import randint as sp_randInt\n",
        "\n",
        "rf_model = RandomForestClassifier(\n",
        "    random_state=RANDOM_STATE,\n",
        "    n_estimators=1500\n",
        ")"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7M6QevFz0F3"
      },
      "source": [
        "cv = CountVectorizer(\n",
        "    lowercase=True,\n",
        "    max_features=5000,\n",
        "    min_df=50,\n",
        "    binary=True,\n",
        "    ngram_range=(1,1),\n",
        "    strip_accents='ascii'\n",
        ")"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBGuwNxmwLpm"
      },
      "source": [
        "rf_pipe = Pipeline(\n",
        "    steps=[\n",
        "           ('preprocessor', cv),\n",
        "           ('model', rf_model)\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLTtMUicwyfC",
        "outputId": "f3cfce91-33e5-4896-8b73-591a08d3f332",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "rf_pipe.fit(train_df['text'], train_df['target'])\n",
        "\n",
        "train_df['target_prediction'] = rf_pipe.predict(train_df['text'])\n",
        "print('Training accuracy is', metrics.accuracy_score(train_df['target'], train_df['target_prediction']))\n",
        "\n",
        "val_df['target_prediction'] = rf_pipe.predict(val_df['text'])\n",
        "print('Validation accuracy is', metrics.accuracy_score(val_df['target'], val_df['target_prediction']))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy is 1.0\n",
            "Validation accuracy is 0.8878980891719745\n",
            "CPU times: user 30.7 s, sys: 98.8 ms, total: 30.8 s\n",
            "Wall time: 30.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djGUehOrb5JU"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeOVZCiBxAR5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yFvpKbmb5JU"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mjOv6gLb5JU"
      },
      "source": [
        "In this notebook we learned about natural language processing - how you can find patterns in the text using regular expressions and how you can convert that text into a vector form by tokenizing the text and encoding the existence (or not) of specific textual patterns (such as words, word pairs). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajF51kAGb5JU"
      },
      "source": [
        "## Further research\n",
        "\n",
        "- https://developers.google.com/edu/python/regular-expressions\n",
        "- https://scikit-learn.org/stable/modules/naive_bayes.html\n",
        "- https://www.kdnuggets.com/2020/07/spam-filter-python-naive-bayes-scratch.html"
      ]
    }
  ]
}